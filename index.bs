<pre class="metadata">
Title: Shape detection in Images
Status: ED
ED: https://wicg.github.io/shape-detection-api
Shortname: shape-detection-api
Level: 1
Editor: Miguel Casas-Sanchez, Google Inc., mcasas@google.com
Abstract: This document describes an API for surfacing accelerated capabilities for detection of shapes in still images or live image feeds. The shapes can be, but are not limited to, human faces.
Group: wicg
!Participate: <a href="https://www.w3.org/community/wicg/">Join the W3C Community Group</a>
!Participate: <a href="https://github.com/WICG/shape-detection-api">Fix the text through GitHub</a>
</pre>

<style>
table {
  border-collapse: collapse;
  border-left-style: hidden;
  border-right-style: hidden;
  text-align: left;
}
table caption {
  font-weight: bold;
  padding: 3px;
  text-align: left;
}
table td, table th {
  border: 1px solid black;
  padding: 3px;
}
</style>

# Introduction # {#introduction}

Photos and images constitute the largest chunk of the Web, and many include recognisable features, such as human faces or QR codes. Detecting these features is computationally expensive, but would lead to interesting use cases e.g. face tagging or detection of high saliency areas. Also, users interacting with WebCams or other Video Capture Devices have become accustomed to camera-like features such as the ability to focus directly on human faces on the screen of their devices. This is particularly true in the case of mobile devices, where hardware manufacturers have long been supporting these features. Unfortunately, Web Apps do not yet have access to these hardware capabilities, which makes the use of computationally demanding libraries necessary.

# Shape detection in the wild # {#shape-detection}

Object-class detection in general consists on "the task is to find the locations and sizes of all objects in an image that belong to a given class. Examples include upper torsos, pedestrians, and cars." [[wikipedia]] . Face detection, on the other hand, focuses on detecting near-front facing human faces. A widespread class of detection algorithms use a hunting algorithm that tries to match a cascade of classifiers in several areas of the image and for several potential object sizes, which turns the process into extremely computationally complex. It is not the idea here to compare those algorithms, nor to offer a software fallback implementation of any of them for the Web, but to offer the available hardware capabilities, if any, to the Web Applications.

<p class="note">
Note that Face Detection (resp., Object) is not the same as Face Tracking nor Face Recognition, albeit those operations are usually interrelated.
</p>

<p class="note">Some Web Apps -gasp- run Face Detection in Javascript. A performance comparison of some such libraries can be found in <a href=>https://github.com/mtschirs/js-objectdetect#performance>mtschirs GitHub repo</a>
</p>

Some use cases of having object/face detection in the Web:

* Live video feeds would like to identify faces in a picture/video as highly salient areas to e.g. give hints to image or video encoders.
* Social network pages would like to quickly identify the human faces in a picture/video and offer the user e.g. the possibility of tagging which name corresponds to which face.
* Face detection is the first step before Face Recognition: detected faces are used for the recognition phase, greatly speeding the process.
* Fun! you can map glasses, funny hats and other overlays on top of the detected faces

Finally, note that using a particular Face/Object Detector does not preclude using others; in this case the hardware provided results can, e.g. be used as precursor or in parallel to user-defined ones.

# Shape Detection API # {#api}

Individual browsers MAY provide the capabilitiy to create a {{Detector}} of {{ShapeDetectorType}}.

<pre class="idl">
[NoInterfaceObject, exposed=Window,Worker]
interface Detector {
    Promise &lt;sequence&lt;DetectedObject>> detect(ImageBitmapSource image);
};

[Constructor(optional FaceDetectorOptions faceDetectorOptions)]
interface FaceDetector {
    // face detector specific attributes and methods
};
FaceDetector implements Detector;

partial interface Navigator {
  Promise&lt;Detector> getShapeDetector(ShapeDetectorType type);
};
</pre>

<pre class="idl">
enum ShapeDetectorType {
  "face",
  "qr",
  // etc...
};

dictionary ShapeExtras {
  float confidence = 0.0;
  // etc...
};

dictionary FaceDetectorOptions {
  DOMRect minDetectedFaceSize;
  // etc...
};

interface DetectedObject {
  readonly attribute ShapeDetectorType type;
  readonly attribute DOMRect boundingBox;
  readonly attribute ShapeExtras extras;
};

typedef (HTMLImageElement or
         HTMLVideoElement or
         HTMLCanvasElement or
         Blob or
         ImageData or
         ImageBitmap) ImageBitmapSource;

</pre>

# Examples # {#examples}

<div class="example" highlight="javascript">
<pre>
navigator.getShapeDetector('face')
.catch(() => {
  console.error("Face Detection most likely not supported");
}).then(detector => {
  // Assume |theImage| is e.g. a &lt;img> content, or a Blob.
	return detector.detect(theImage);
}).then(detectedShapes => {
  for (const shape of detectedShapes) {
    console.assert(shape.type == 'face', "Detected object should be a face");
    console.log( ' face detected at ' +
        '(${shape.boundingBox.x}, ${shape.boundingBox.y}),' +
        ' size ${shape.boundingBox.width}x${shape.boundingBox.height}');
  }
})
</pre>
</div>

<pre class="anchors">
spec: ECMAScript; urlPrefix: https://tc39.github.io/ecma262/#
    type: interface
        text: Array; url: sec-array-objects
        text: Promise; url:sec-promise-objects
        text: TypeError; url: sec-native-error-types-used-in-this-standard-typeerror
</pre>

<pre class="link-defaults">
spec: html
    type: dfn
        text: allowed to show a popup
        text: in parallel
        text: incumbent settings object
</pre>

<pre class="biblio">
{
  "wikipedia": {
      "href": "https://en.wikipedia.org/wiki/Face_detection",
      "title": "Face Detection Wikipedia Entry",
      "publisher": "Wikipedia",
      "date": "15 August 2016"
  }
}
</pre>

